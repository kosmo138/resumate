{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeyword_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     GoogleSearchScraper,\n\u001b[0;32m      4\u001b[0m     KeywordExtractor,\n\u001b[0;32m      5\u001b[0m     TextAnalyzer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeyword_bak\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m insert_keyword_results\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'app'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from app.service.keyword_class import (\n",
    "    GoogleSearchScraper,\n",
    "    KeywordExtractor,\n",
    "    TextAnalyzer,\n",
    ")\n",
    "import json\n",
    "from app.service.keyword_bak import insert_keyword_results\n",
    "\n",
    "\n",
    "def extract_keywords(csv_file_path):\n",
    "    # Word2Vec 모델 경로\n",
    "    model_path = \"wiki.model\"\n",
    "    # 목표 단어 리스트\n",
    "    target_words = [\n",
    "        \"인재\",\n",
    "        \"소통\",\n",
    "        \"능력\",\n",
    "        \"책임\",\n",
    "        \"성실\",\n",
    "        \"도전\",\n",
    "        \"열정\",\n",
    "        \"꿈\",\n",
    "        \"사람\",\n",
    "        \"다양\",\n",
    "        \"창의\",\n",
    "        \"혁신\",\n",
    "        \"전문\",\n",
    "        \"기술\",\n",
    "        \"지식\",\n",
    "        \"해결\",\n",
    "        \"리더십\",\n",
    "        \"팀워크\",\n",
    "        \"목표\",\n",
    "        \"정직\",\n",
    "        \"도덕\",\n",
    "        \"학습\",\n",
    "        \"성장\",\n",
    "        \"비전\",\n",
    "    ]\n",
    "\n",
    "    # GoogleSearchScraper, KeywordExtractor, TextAnalyzer 객체 생성\n",
    "    scraper = GoogleSearchScraper()\n",
    "    extractor = KeywordExtractor(model_path)\n",
    "    analyzer = TextAnalyzer()\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    try:\n",
    "        with open(csv_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            for row in csv_reader:\n",
    "                if row:  # 빈 행이 아닌 경우에만 회사 이름 데이터를 가져옴\n",
    "                    company_name = row[0]\n",
    "                    print(f\"Processing company: {company_name}\")\n",
    "\n",
    "                    # 회사 이름을 사용하여 검색 결과 URL 가져오기\n",
    "                    url = scraper.get_first_search_result_url(company_name)\n",
    "                    if url:\n",
    "                        # URL에서 HTML 내용을 추출하여 명사 추출\n",
    "                        nouns = analyzer.extract_nouns_from_html(url)\n",
    "                        if nouns:\n",
    "                            # 추출된 명사를 사용하여 관련 키워드 추출\n",
    "                            related_keywords = extractor.extract_related_keywords(\n",
    "                                nouns, target_words\n",
    "                            )\n",
    "                            if related_keywords:\n",
    "                                print(\n",
    "                                    f\"Related keywords for {company_name}: {related_keywords}\"\n",
    "                                )\n",
    "                                # 추출된 데이터를 딕셔너리 형태로 저장\n",
    "                                company_data = {\n",
    "                                    \"company\": company_name,\n",
    "                                    \"keywords\": list(related_keywords),\n",
    "                                }\n",
    "                                extracted_data.append(company_data)\n",
    "                            else:\n",
    "                                print(f\"No related keywords found for {company_name}\")\n",
    "                        else:\n",
    "                            print(f\"No nouns extracted from HTML for {company_name}\")\n",
    "                    else:\n",
    "                        print(f\"Failed to get search result URL for {company_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def main(csv_file_path):\n",
    "    extracted_data = extract_keywords(csv_file_path)\n",
    "    # 추출된 데이터를 JSON 형식으로 출력\n",
    "    insert_keyword_results(extracted_data)\n",
    "    print(json.dumps(extracted_data, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"companies.csv\"  # CSV 파일 경로\n",
    "    main(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
